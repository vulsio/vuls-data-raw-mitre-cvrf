{
  "title": "CVE-2023-29374",
  "cve": "CVE-2023-29374",
  "notes": {
    "description": "In LangChain through 0.0.131, the LLMMathChain chain allows prompt injection attacks that can execute arbitrary code via the Python exec method.",
    "published": "2023-04-04",
    "modified": "2023-04-04"
  },
  "references": [
    {
      "url": "https://github.com/hwchase17/langchain/issues/1026",
      "description": "MISC:https://github.com/hwchase17/langchain/issues/1026"
    },
    {
      "url": "https://github.com/hwchase17/langchain/issues/814",
      "description": "MISC:https://github.com/hwchase17/langchain/issues/814"
    },
    {
      "url": "https://github.com/hwchase17/langchain/pull/1119",
      "description": "MISC:https://github.com/hwchase17/langchain/pull/1119"
    },
    {
      "url": "https://twitter.com/rharang/status/1641899743608463365/photo/1",
      "description": "MISC:https://twitter.com/rharang/status/1641899743608463365/photo/1"
    }
  ]
}
